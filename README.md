# ğŸ¤– Task 2: Transformer News Classification

Entrenamiento y comparaciÃ³n de modelos transformer (RoBERTa, DeBERTa, ModernBERT) en el dataset AG News.

---

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema de clasificaciÃ³n de noticias usando tres modelos transformer state-of-the-art. El objetivo es comparar el rendimiento de diferentes arquitecturas en la tarea de clasificaciÃ³n multiclase de noticias.

### ğŸ¯ Objetivos

1. Entrenar 3 modelos transformer en AG News dataset
2. Evaluar y comparar F1-scores
3. Analizar rendimiento por categorÃ­a
4. Generar visualizaciones comparativas
5. (Bonus) Clasificar noticias RPP con LLM

---

## ğŸ“Š Dataset: AG News

- **Fuente**: [Hugging Face - AG News](https://huggingface.co/datasets/ag_news)
- **Ejemplos**: 120,000 noticias
- **CategorÃ­as**: 4 clases
  - 0: World (Internacional)
  - 1: Sports (Deportes)
  - 2: Business (Negocios)
  - 3: Science/Tech (Ciencia/TecnologÃ­a)

### Split del Dataset

```
Train:      70% (84,000 ejemplos)
Validation: 15% (18,000 ejemplos)
Test:       15% (18,000 ejemplos)
```

---

## ğŸ¤– Modelos Implementados

### 1. RoBERTa
- **Model ID**: `roberta-base`
- **ParÃ¡metros**: 125M
- **Arquitectura**: BERT optimizado
- **Ventaja**: Robusto, bien establecido

### 2. DeBERTa
- **Model ID**: `microsoft/deberta-v3-small`
- **ParÃ¡metros**: 86M
- **Arquitectura**: Disentangled attention
- **Ventaja**: Eficiente, buen ratio desempeÃ±o/tamaÃ±o

### 3. ModernBERT
- **Model ID**: `answerdotai/ModernBERT-base`
- **ParÃ¡metros**: 110M
- **Arquitectura**: BERT modernizado (2024)
- **Ventaja**: Arquitectura actualizada

---

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos Previos

- Python 3.10+
- Google Colab (recomendado) o entorno local con GPU
- Google Drive (para almacenamiento persistente)

### 1ï¸âƒ£ Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Ejecutar en Google Colab

1. Subir `agnews_train_eval.ipynb` a Google Colab
2. Configurar GPU: `Runtime â†’ Change runtime type â†’ GPU (T4)`
3. Montar Google Drive
4. Ejecutar todas las celdas: `Runtime â†’ Run all`

### 3ï¸âƒ£ Estructura de Archivos

El notebook genera automÃ¡ticamente:

```
H:\Mi unidad\News_Classification-lab\
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ roberta/best/      # Modelo RoBERTa entrenado
â”‚   â”œâ”€â”€ deberta/best/      # Modelo DeBERTa entrenado
â”‚   â””â”€â”€ modernbert/best/   # Modelo ModernBERT entrenado
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ split_info.json    # InformaciÃ³n del split
â”‚   â””â”€â”€ rpp_classified.json # (Bonus) Noticias RPP clasificadas
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ test_results.json  # MÃ©tricas de evaluaciÃ³n
â”‚   â”œâ”€â”€ summary_table.csv  # Tabla resumen
â”‚   â””â”€â”€ analysis_report.md # Reporte de anÃ¡lisis
â””â”€â”€ figures/
    â”œâ”€â”€ f1_comparison.png      # ComparaciÃ³n entre modelos
    â”œâ”€â”€ f1_per_class.png       # F1 por categorÃ­a
    â””â”€â”€ f1_comparison_llm.png  # (Bonus) ComparaciÃ³n vs LLM
```

---

## ğŸ“ˆ Resultados

### F1-Scores en Test Set

| Modelo | F1 (Macro) | F1 (Weighted) | Tiempo Entrenamiento |
|--------|------------|---------------|---------------------|
| RoBERTa | 0.9495 | 0.9495 | 34 min |
| ModernBERT | 0.9463 | 0.9463 | 50 min |
| DeBERTa | 0.9444 | 0.9444 | 33 min |

### F1-Score por CategorÃ­a

```
World:        0.94
Sports:       0.96
Business:     0.93
Science/Tech: 0.95
```

---

## âš¡ VersiÃ³n RÃ¡pida (10% Dataset)

Para desarrollo y pruebas rÃ¡pidas, usa `agnews_train_eval_FAST.ipynb`:

- **Dataset**: 10% del original (12,000 ejemplos)
- **Tiempo**: 21 min (GPU) / 56 min (CPU)
- **F1 Score**: ~0.90-0.93 (ligeramente menor pero vÃ¡lido)

### Modificar TamaÃ±o de Muestra

```python
# En la celda de split, cambiar:
sample_size = int(len(dataset['train']) * 0.10)  # 10%

# A:
sample_size = int(len(dataset['train']) * 0.25)  # 25% â†’ 35 min
sample_size = int(len(dataset['train']) * 0.50)  # 50% â†’ 60 min
sample_size = int(len(dataset['train']) * 1.00)  # 100% â†’ 90 min
```

---

## ğŸ Bonus Task: ClasificaciÃ³n LLM

ClasificaciÃ³n de 50 noticias de RPP (Task 1) usando ChatGPT y comparaciÃ³n con modelos entrenados.

### Requisitos

- OpenAI API Key
- Noticias de RPP (de Task 1)
- CrÃ©ditos en OpenAI (~$0.50)

### ConfiguraciÃ³n

```python
# OpciÃ³n 1: Colab Secrets (recomendado)
# ğŸ”‘ â†’ Add secret: OPENAI_API_KEY

# OpciÃ³n 2: Input manual
from getpass import getpass
OPENAI_API_KEY = getpass('API Key: ')
```

### Resultados

- F1-Score: ComparaciÃ³n modelos vs LLM
- AnÃ¡lisis de divergencias
- VisualizaciÃ³n comparativa

---

## ğŸ› ï¸ ConfiguraciÃ³n TÃ©cnica

### HiperparÃ¡metros

```python
{
    'max_length': 128,           # Tokens mÃ¡ximos
    'batch_size': 16,            # Batch size
    'learning_rate': 2e-5,       # Learning rate
    'epochs': 3,                 # Ã‰pocas
    'weight_decay': 0.01,        # RegularizaciÃ³n
    'optimizer': 'adamw_torch'   # Optimizador
}
```

### Hardware Recomendado

- **GPU**: T4 (Google Colab gratis) o superior
- **RAM**: 12GB mÃ­nimo
- **Almacenamiento**: 2GB Drive para modelos

### Tiempos de EjecuciÃ³n

**Con GPU T4:**
```
Setup:              3 min
Entrenamiento:     90 min (3 modelos Ã— 30 min)
EvaluaciÃ³n:         5 min
Visualizaciones:    2 min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:            100 min
```

**Con CPU:**
```
Setup:              5 min
Entrenamiento:    300 min (3 modelos Ã— 100 min)
EvaluaciÃ³n:        15 min
Visualizaciones:    2 min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:            322 min
```

---

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### F1-Score (Macro)

```
F1 = 2 Ã— (precision Ã— recall) / (precision + recall)
F1_macro = promedio de F1 de todas las clases
```

**Usado para**: ComparaciÃ³n principal entre modelos

### F1-Score (Weighted)

```
F1_weighted = promedio ponderado por soporte de clase
```

**Usado para**: AnÃ¡lisis secundario considerando distribuciÃ³n

### Accuracy

```
Accuracy = predicciones correctas / total
```

**Usado para**: Bonus task (alineaciÃ³n con LLM)

---

## ğŸ”§ Troubleshooting

### Error: "CUDA out of memory"

**SoluciÃ³n**:
```python
# Reducir batch size
'batch_size': 8  # en vez de 16
```

### Error: "fused=True requires..."

**SoluciÃ³n**:
```python
# Agregar en TrainingArguments:
optim="adamw_torch"
```

### Error: "Mountpoint must not already contain files"

**SoluciÃ³n**:
```python
# Verificar antes de montar
if os.path.exists('/content/drive/MyDrive'):
    print("âœ… Drive ya montado")
else:
    drive.mount('/content/drive')
```

### Error: "No GPU available"

**SoluciÃ³n**:
```
Runtime â†’ Change runtime type â†’ GPU (T4)
```

### Entrenamiento muy lento

**SoluciÃ³n**:
```python
# Usar versiÃ³n rÃ¡pida (10% dataset)
# O reducir epochs:
'epochs': 2  # en vez de 3
```

---

## ğŸ“ Archivos Principales

### Notebooks

- `agnews_train_eval.ipynb` - VersiÃ³n completa (100% dataset)
- `agnews_train_eval_FAST.ipynb` - VersiÃ³n rÃ¡pida (10% dataset)

### Scripts

- `train_model()` - FunciÃ³n de entrenamiento unificada
- `compute_metrics()` - CÃ¡lculo de F1-scores
- `classify_with_llm()` - ClasificaciÃ³n con ChatGPT

### Outputs

- `test_results.json` - MÃ©tricas detalladas
- `summary_table.csv` - Tabla resumen
- `analysis_report.md` - AnÃ¡lisis completo
- `f1_comparison.png` - GrÃ¡fica comparativa
- `f1_per_class.png` - GrÃ¡fica por categorÃ­a

---

## ğŸ“ Requisitos de Entrega

### âœ… Obligatorios

- [x] Dataset AG News split 70/15/15
- [x] 3 modelos transformer entrenados
- [x] F1-scores calculados (macro y weighted)
- [x] Test set usado solo UNA vez
- [x] GrÃ¡fica de comparaciÃ³n
- [x] Tabla resumen
- [x] Reporte de anÃ¡lisis
- [x] CÃ³digo reproducible

### â­ Bonus (+3 pts)

- [x] ClasificaciÃ³n LLM de noticias RPP
- [x] ComparaciÃ³n modelos vs LLM
- [x] AnÃ¡lisis de divergencias
- [x] VisualizaciÃ³n comparativa

---

## ğŸ“š Referencias

### Datasets

- [AG News Dataset](https://huggingface.co/datasets/ag_news)

### Modelos

- [RoBERTa Paper](https://arxiv.org/abs/1907.11692)
- [DeBERTa Paper](https://arxiv.org/abs/2006.03654)
- [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base)

### LibrerÃ­as

- [Transformers](https://huggingface.co/docs/transformers)
- [Datasets](https://huggingface.co/docs/datasets)
- [PyTorch](https://pytorch.org/)

---

## ğŸ‘¥ Autores

Proyecto desarrollado como parte del curso de Data Science.

---

## ğŸ“„ Licencia

Este proyecto es con fines educativos.

---

## ğŸ†˜ Soporte

Para problemas o preguntas:

1. Revisar secciÃ³n Troubleshooting
2. Verificar que GPU estÃ¡ habilitada
3. Confirmar que Drive estÃ¡ montado
4. Revisar logs de error completos

---

## ğŸ“Š RÃºbrica

| Criterio | Puntos | Status |
|----------|--------|--------|
| Data & Reproducibility | 4 pts | âœ… |
| Task 2: Transformer Models | 6 pts | âœ… |
| Visualization & Comparison | 2 pts | âœ… |
| Bonus: LLM Classification | +3 pts | â­ |
| **Total** | **15 pts** | âœ… |

---

**Desarrollado**: Noviembre 2025  
**Ãšltima actualizaciÃ³n**: 15 de Noviembre, 2025  
**VersiÃ³n**: 1.0  
**Status**: âœ… ProducciÃ³n